{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbSTKJ9uaHoj",
        "outputId": "4f418d03-b0fd-4883-97a8-ad92d0153120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m113.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok tensorflow pillow joblib torch transformers pytorch-tabnet --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"2zELGoE2ygB2rvU3KVHSB5A7qqh_71xvBX1vyBpa2MvGgTdSN\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aMCIDxfaWMb",
        "outputId": "442d4125-fef2-42d4-9a18-e54c50007f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12fUJl-baXmF",
        "outputId": "c1b0227a-8143-42d6-9c23-a641a52c0efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import joblib\n",
        "import torch\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# ===================== BASE PATH =====================\n",
        "BASE_PATH = \"/content/drive/MyDrive/Klasifikasi_Kategori_Judul_Berita/models\"\n",
        "\n",
        "# ===================== PAGE CONFIG =====================\n",
        "st.set_page_config(\n",
        "    page_title=\"Dashboard Klasifikasi Kategori Judul Berita\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "st.title(\"ðŸ“° Dashboard Klasifikasi Kategori Judul Berita\")\n",
        "st.write(\"Prediksi menggunakan **LSTM**, **DistilBERT**, dan **IndoBERT**\")\n",
        "\n",
        "# ===================== CACHE MODELS =====================\n",
        "@st.cache_resource\n",
        "def load_lstm_model():\n",
        "    tf.keras.backend.clear_session()\n",
        "    model = load_model(f\"{BASE_PATH}/lstm/model_lstm.h5\", compile=False)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "                  loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    with open(f\"{BASE_PATH}/lstm/tokenizer_lstm.json\", \"r\") as f:\n",
        "        tokenizer_json = f.read()\n",
        "        tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(tokenizer_json)\n",
        "    label_encoder = joblib.load(f\"{BASE_PATH}/lstm/label_encoder_lstm.pkl\")\n",
        "    return model, tokenizer, label_encoder\n",
        "\n",
        "@st.cache_resource\n",
        "def load_distilbert_model():\n",
        "    model_path = f\"{BASE_PATH}/distilbert\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "    label_encoder = joblib.load(f\"{model_path}/label_encoder.pkl\")\n",
        "    return tokenizer, model, label_encoder\n",
        "\n",
        "@st.cache_resource\n",
        "def load_indobert_model():\n",
        "    model_path = f\"{BASE_PATH}/indobert\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "    label_encoder = joblib.load(f\"{model_path}/label_encoder.pkl\")\n",
        "    return tokenizer, model, label_encoder\n",
        "\n",
        "# ===================== LOAD MODELS =====================\n",
        "lstm_model, lstm_tokenizer, lstm_label_encoder = load_lstm_model()\n",
        "distil_tokenizer, distil_model, distil_label_encoder = load_distilbert_model()\n",
        "indo_tokenizer, indo_model, indo_label_encoder = load_indobert_model()\n",
        "\n",
        "# ===================== TABS =====================\n",
        "tab_lstm, tab_distil, tab_indo = st.tabs([\"ðŸŸ¢ LSTM\", \"ðŸŸ¡ DistilBERT\", \"ðŸ”µ IndoBERT\"])\n",
        "\n",
        "# ===================== LSTM =====================\n",
        "with tab_lstm:\n",
        "    st.header(\"ðŸŸ¢ Prediksi dengan LSTM\")\n",
        "    text_input_lstm = st.text_area(\"Masukkan judul berita:\", key=\"lstm_text\", height=150)\n",
        "    if st.button(\"Prediksi LSTM\", key=\"btn_lstm\"):\n",
        "        if text_input_lstm.strip() == \"\":\n",
        "            st.warning(\"Teks tidak boleh kosong\")\n",
        "        else:\n",
        "            seq = lstm_tokenizer.texts_to_sequences([text_input_lstm])\n",
        "            pad_seq = pad_sequences(seq, maxlen=100, padding=\"post\", truncating=\"post\")\n",
        "            pred = lstm_model.predict(pad_seq)\n",
        "            label = lstm_label_encoder.inverse_transform([np.argmax(pred)])[0]\n",
        "            confidence = np.max(pred) * 100\n",
        "            st.success(f\"Hasil Prediksi: **{label}**\")\n",
        "            st.info(f\"Confidence: **{confidence:.2f}%**\")\n",
        "\n",
        "# ===================== DistilBERT =====================\n",
        "with tab_distil:\n",
        "    st.header(\"ðŸŸ¡ Prediksi dengan DistilBERT\")\n",
        "    text_input_distil = st.text_area(\"Masukkan judul berita:\", key=\"distil_text\", height=150)\n",
        "    if st.button(\"Prediksi DistilBERT\", key=\"btn_distil\"):\n",
        "        if text_input_distil.strip() == \"\":\n",
        "            st.warning(\"Teks tidak boleh kosong\")\n",
        "        else:\n",
        "            inputs = distil_tokenizer(text_input_distil, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n",
        "            with torch.no_grad():\n",
        "                outputs = distil_model(**inputs)\n",
        "            probs = torch.softmax(outputs.logits, dim=1)\n",
        "            pred_idx = torch.argmax(probs, dim=1).item()\n",
        "            label = distil_label_encoder.inverse_transform([pred_idx])[0]\n",
        "            confidence = probs[0][pred_idx].item() * 100\n",
        "            st.success(f\"Hasil Prediksi: **{label}**\")\n",
        "            st.info(f\"Confidence: **{confidence:.2f}%**\")\n",
        "\n",
        "# ===================== IndoBERT =====================\n",
        "with tab_indo:\n",
        "    st.header(\"ðŸ”µ Prediksi dengan IndoBERT\")\n",
        "    text_input_indo = st.text_area(\"Masukkan judul berita:\", key=\"indo_text\", height=150)\n",
        "    if st.button(\"Prediksi IndoBERT\", key=\"btn_indo\"):\n",
        "        if text_input_indo.strip() == \"\":\n",
        "            st.warning(\"Teks tidak boleh kosong\")\n",
        "        else:\n",
        "            inputs = indo_tokenizer(text_input_indo, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n",
        "            with torch.no_grad():\n",
        "                outputs = indo_model(**inputs)\n",
        "            probs = torch.softmax(outputs.logits, dim=1)\n",
        "            pred_idx = torch.argmax(probs, dim=1).item()\n",
        "            label = indo_label_encoder.inverse_transform([pred_idx])[0]\n",
        "            confidence = probs[0][pred_idx].item() * 100\n",
        "            st.success(f\"Hasil Prediksi: **{label}**\")\n",
        "            st.info(f\"Confidence: **{confidence:.2f}%**\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Eu_XFeEaPyt",
        "outputId": "b10014a4-6fa5-4c62-9f90-c4e123292f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py --server.port 8501 --server.address 0.0.0.0 &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "HviqRvODa3KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"ðŸ”— Streamlit URL:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyQenz8ra586",
        "outputId": "eae258d2-babc-4b3a-8952-113f31106139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”— Streamlit URL: NgrokTunnel: \"https://e84b4dfb9e0b.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill ngrok"
      ],
      "metadata": {
        "id": "aCrHBLnia7Qw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5b980c4-a641-4313-8991-4d23995abca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-12-22T04:56:30+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-e8ae3367-01a4-437c-ae65-95c81872e0d7 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-12-22T04:56:30+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-8501-e8ae3367-01a4-437c-ae65-95c81872e0d7 err=\"failed to start tunnel: session closed\"\n"
          ]
        }
      ]
    }
  ]
}