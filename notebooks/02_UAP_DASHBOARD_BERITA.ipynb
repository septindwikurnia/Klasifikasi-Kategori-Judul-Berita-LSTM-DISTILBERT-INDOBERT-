{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbSTKJ9uaHoj",
        "outputId": "a29c399c-9629-4761-8161-b0986743308a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok tensorflow pillow joblib torch transformers pytorch-tabnet --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"2zELGoE2ygB2rvU3KVHSB5A7qqh_71xvBX1vyBpa2MvGgTdSN\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aMCIDxfaWMb",
        "outputId": "45996741-dd38-4b91-bee5-dd490a74c333"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12fUJl-baXmF",
        "outputId": "a778a702-95be-467e-bff4-ff4db7ab9933"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import joblib\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# ===================== BASE PATH =====================\n",
        "BASE_PATH = \"/content/drive/MyDrive/Klasifikasi_Kategori_Judul_Berita/models\"\n",
        "\n",
        "# ===================== PAGE CONFIG =====================\n",
        "st.set_page_config(\n",
        "    page_title=\"Dashboard Klasifikasi Judul Berita\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "st.title(\"ðŸ“° Dashboard Klasifikasi Kategori Judul Berita\")\n",
        "st.caption(\"Prediksi kategori judul berita menggunakan model Deep Learning & Transformer\")\n",
        "\n",
        "# ===================== LOAD MODELS =====================\n",
        "@st.cache_resource\n",
        "def load_lstm():\n",
        "    tf.keras.backend.clear_session()\n",
        "    model = load_model(f\"{BASE_PATH}/lstm/model_lstm.h5\", compile=False)\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
        "    tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(\n",
        "        open(f\"{BASE_PATH}/lstm/tokenizer_lstm.json\").read()\n",
        "    )\n",
        "    label_encoder = joblib.load(f\"{BASE_PATH}/lstm/label_encoder_lstm.pkl\")\n",
        "    return model, tokenizer, label_encoder\n",
        "\n",
        "@st.cache_resource\n",
        "def load_transformer(name):\n",
        "    path = f\"{BASE_PATH}/{name}\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(path)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(path)\n",
        "    label_encoder = joblib.load(f\"{path}/label_encoder.pkl\")\n",
        "    return tokenizer, model, label_encoder\n",
        "\n",
        "lstm_model, lstm_tokenizer, lstm_le = load_lstm()\n",
        "distil_tok, distil_model, distil_le = load_transformer(\"distilbert\")\n",
        "indo_tok, indo_model, indo_le = load_transformer(\"indobert\")\n",
        "\n",
        "# ===================== SIDEBAR (KANAN) =====================\n",
        "with st.sidebar:\n",
        "    st.header(\"âš™ï¸ Model Klasifikasi\")\n",
        "\n",
        "    model_choice = st.radio(\n",
        "        \"Pilih Model\",\n",
        "        [\"LSTM\", \"DistilBERT\", \"IndoBERT\"]\n",
        "    )\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.subheader(\"ðŸ“Š Ringkasan Model\")\n",
        "\n",
        "    model_info = {\n",
        "        \"LSTM\": (\"84%\", \"Cepat & ringan\"),\n",
        "        \"DistilBERT\": (\"90%\", \"Konteks lebih baik\"),\n",
        "        \"IndoBERT\": (\"91%\", \"Akurasi tertinggi\")\n",
        "    }\n",
        "\n",
        "    acc, desc = model_info[model_choice]\n",
        "    st.metric(\"Akurasi Model\", acc)\n",
        "    st.caption(desc)\n",
        "\n",
        "# ===================== MAIN AREA =====================\n",
        "st.subheader(\"âœï¸ Masukkan Judul Berita\")\n",
        "text_input = st.text_area(\"Judul Berita\", height=120)\n",
        "\n",
        "if st.button(\"ðŸ” Prediksi Kategori\"):\n",
        "    if text_input.strip() == \"\":\n",
        "        st.warning(\"Teks tidak boleh kosong\")\n",
        "    else:\n",
        "        # ===== LSTM =====\n",
        "        if model_choice == \"LSTM\":\n",
        "            seq = lstm_tokenizer.texts_to_sequences([text_input])\n",
        "            pad_seq = pad_sequences(seq, maxlen=100, padding=\"post\")\n",
        "            pred = lstm_model.predict(pad_seq)\n",
        "            idx = np.argmax(pred)\n",
        "            label = lstm_le.inverse_transform([idx])[0]\n",
        "            conf = np.max(pred) * 100\n",
        "\n",
        "        # ===== DistilBERT =====\n",
        "        elif model_choice == \"DistilBERT\":\n",
        "            inputs = distil_tok(text_input, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "            with torch.no_grad():\n",
        "                outputs = distil_model(**inputs)\n",
        "            probs = torch.softmax(outputs.logits, dim=1)\n",
        "            idx = torch.argmax(probs, dim=1).item()\n",
        "            label = distil_le.inverse_transform([idx])[0]\n",
        "            conf = probs[0][idx].item() * 100\n",
        "\n",
        "        # ===== IndoBERT =====\n",
        "        else:\n",
        "            inputs = indo_tok(text_input, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "            with torch.no_grad():\n",
        "                outputs = indo_model(**inputs)\n",
        "            probs = torch.softmax(outputs.logits, dim=1)\n",
        "            idx = torch.argmax(probs, dim=1).item()\n",
        "            label = indo_le.inverse_transform([idx])[0]\n",
        "            conf = probs[0][idx].item() * 100\n",
        "\n",
        "        st.success(f\"ðŸ“° **Kategori: {label}**\")\n",
        "        st.info(f\"ðŸ“ˆ Confidence: **{conf:.2f}%**\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Eu_XFeEaPyt",
        "outputId": "1b4d15b6-3f26-436e-fac2-d5fdd2e55026"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py --server.port 8501 --server.address 0.0.0.0 &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "HviqRvODa3KT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"ðŸ”— Streamlit URL:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyQenz8ra586",
        "outputId": "d421c4bf-2eee-4ed3-c654-b2d183a97840"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”— Streamlit URL: NgrokTunnel: \"https://c082e2cf84c7.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill ngrok"
      ],
      "metadata": {
        "id": "aCrHBLnia7Qw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5b896f8-7272-4c44-8dbb-7f0902a26f9e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-12-24T15:11:28+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-3749fe59-5d28-424f-b6ad-2d129fee2870 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-12-24T15:11:28+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-8501-3749fe59-5d28-424f-b6ad-2d129fee2870 err=\"failed to start tunnel: session closed\"\n"
          ]
        }
      ]
    }
  ]
}